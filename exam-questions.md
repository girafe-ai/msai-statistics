# MSAI Statistics Exam Questions

1. What is statistical inference? Parametric and nonparametric models, parameter space, nuisance parameters. Statistics (statistical functionals).
2. Point estimation of parameters. Bias, biased vs unbiased estimates. Consistency, consistent estimates. Variance of an estimater. Mean Square Error (MSE) of an estimator = bias^2 + variance.
4. Empirical distribution functions (CDF and PDF), its expectation, variance and MSE. Glivenko-Cantelli, DKW-inequality.
5. The Bootstrap, the Jackknife.
6. The Method of Moments (MOM), its good properties. MOM-estimates for Bernoulli, Normal.
7. The Method of Maximum Likelihood (MLE), its good properties. MLE-estimates for Bernoulli, for mu of Normal.
8. The Delta method.
9. Multiparameter models, Fisher information matrix. Example of the Normal (two parameters, mu and sigma).
10. Sufficient statistics, Rao-Blackwell theorem (only statement).
11. Exponential families: natural parameters & sufficient statistics. 
12. The EM algorithm for computing MLE.
13. Hypothesis testing: null/alternative, simple/composite hypotheses, one-/two- sided tests. Types of errors, power function, effect size.
14. The Wald test. Asymptotic normality.
15. Chi squared distribution, Chi squared test. Goodnes-of-fit tests.
17. The Likelihood Ratio test. The Neyman-Pearson lemma.
18. Testing multiple hypotheses: Bonferroni, Benjamini-Hochberg.
19. Student's t-distribution, the t-test.
20. Bayesian inference â€“ likelihood, prior, posterior, evidence. Beta-binomial model, conjugate distributions
21. Simple linear regression. Least squares and maximum likelihood.
22. Properties of least squares (consistency, asymptotic normality). Multiple regression, pseudoinverse.
23. Logistic regression.
24. Testing for independence: likelihood ratio for 2 binary vars, Chi squared test for independence.
25. Causal inference, the Counterfactual model
26. Kernel Density Estimators (KDE). Bias-variance tradeoff for it.